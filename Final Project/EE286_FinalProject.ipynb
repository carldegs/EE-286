{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/carldegs/EE-286/blob/master/EE286_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ciGSB0J4Nb0Q"
   },
   "source": [
    "# Music Genre Classifier\n",
    "\n",
    "Narz Marbeth David 2005-09925\n",
    "Carl Justin de Guia 2011-06521\n",
    "\n",
    "## Introduction\n",
    "// TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LF0UpdlULB8o",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# feature extractoring and preprocessing data\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "#Keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W1-gyeNjNZqK"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset used for training this genre classifier is from the Million Song Dataset [2]. To access the dataset, an AWS instance was started and mounted with the Million Song Dataset. The dataset contains features derived by the Echo Nest API currently documented in Spotify's repositories [4]. The fields will be detailed further in the Feature Extraction section. Additionally, a genre ground truth was provided in [3] to assign genre labels to each song in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JmX3-I-HPWFB"
   },
   "outputs": [],
   "source": [
    "# TODO: Import dataset and show graphs and stuff\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "## The following shows how a track is organized in the dataset \n",
    "dataset_path = r\"/mnt/snap/MillionSongDatabase/data\"\n",
    "\n",
    "def get_track_path(trackId, dataset_path):\n",
    "    track_path = os.path.join(dataset_path, trackId[2],trackId[3], trackId[4]);\n",
    "    return track_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the genre mapping table\n",
    "genre_map = pd.read_csv('msd-MAGD-genreAssignment.cls', comment='#', sep='\\t', header=None, usecols=[0,1], names=['TrackId', 'Genre'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vRxjUMerPaSR"
   },
   "source": [
    "## Feature Extraction\n",
    "\n",
    "The following features are extracted from the training set: \n",
    "\n",
    "- Tempo\n",
    "- Average Beat Period\n",
    "- Within 30 seconds of the song:\n",
    "    - Timbre Coefficients\n",
    "    - Pitch Classes\n",
    "    - Intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This shows what features are available per track \n",
    "\n",
    "def print_track_details(trackId):\n",
    "    trackPath = get_track_path(trackId, dataset_path)\n",
    "    filename = os.path.join(trackPath, trackId + \".h5\")\n",
    "    with hdf5_getters.open_h5_file_read(filename) as h5:\n",
    "        numSongs = hdf5_getters.get_num_songs(h5)\n",
    "        getters = list(filter(lambda x: x[:4] == 'get_', hdf5_getters.__dict__.keys()))\n",
    "        getters.remove(\"get_num_songs\") # special case\n",
    "        for getter in getters:\n",
    "            res = hdf5_getters.__getattribute__(getter)(h5,0)\n",
    "            if res.__class__.__name__ == 'ndarray':\n",
    "                print(getter[4:]+\": shape =\",res.shape)\n",
    "            else:\n",
    "                print(getter[4:]+\":\",res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timbre \n",
    "\n",
    "The timbre feature is a vector that includes 12 unbounded values roughly centered around 0. Those values are high level abstractions of the spectral surface, ordered by degree of importance. The actual timbre of the segment is best described as a linear combination of these 12 basis functions weighted by the coefficient values: \n",
    "\n",
    "timbre = c1 x b1 + c2 x b2 + â€¦ + c12 x b12, \n",
    "\n",
    "where c1 to c12 represent the 12 coefficients and b1 to b12 the 12 basis functions.[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Construct training set headers\n",
    "headers = [\"trackId\", \"tempo\"]\n",
    "segment_timbre_cols = []\n",
    "for i in range(20):\n",
    "    for j in range(12):\n",
    "        ## Timbre column := \"seg_timbre_\" + seg_id + \"_\" + t_coeff_id\n",
    "        segment_timbre_col = \"seg_timbre_%d_%d\"%(i,j)\n",
    "        segment_timbre_cols.append(segment_timbre_col)\n",
    "        headers.append(segment_timbre_col)\n",
    "segment_pitches_cols = []        \n",
    "for i in range(20):\n",
    "    for j in range(12):\n",
    "        ## Timbre column := \"seg_pitches_\" + seg_id + \"_\" + pitch_class_id\n",
    "        segment_pitches_col = \"seg_pitches_%d_%d\"%(i, j)\n",
    "        segment_pitches_cols.append(segment_pitches_col)\n",
    "        headers.append(segment_pitches_col)\n",
    "segment_loudness_cols = []    \n",
    "for i in range(20):\n",
    "    segment_loudness_col = \"seg_loudness_%d\"%(i)\n",
    "    segment_loudness_cols.append(segment_loudness_col)\n",
    "    headers.append(segment_loudness_col)\n",
    "headers.append(\"ave_beat_period\")    \n",
    "headers.append(\"label\")\n",
    "df = pd.DataFrame(columns=headers)\n",
    "df\n",
    "len(segment_timbre_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-f01721c99293>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0ms_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%f'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegments_timbre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrackId\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtempo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%f'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegments_timbre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "trackId='TRAAAAK128F9318786'\n",
    "filename = os.path.join(get_track_path(trackId, dataset_path), trackId + \".h5\")\n",
    "track = Track(trackId, filename)\n",
    "track.setGenre('Pop')\n",
    "track.extractFeatures()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from Track import Track\n",
    "\n",
    "## Generate training set per Genre\n",
    "genre_set = ['Pop_Rock', \n",
    "             'RnB',\n",
    "             'Classical',\n",
    "             'Blues',\n",
    "             'Electronic',\n",
    "             'Latin',\n",
    "             'Jazz',\n",
    "             'Rap',\n",
    "             'Religious']\n",
    "\n",
    "## Write CSV headers of training sets\n",
    "#for genre in genre_set:\n",
    "#    with open(genre + '.csv', 'w') as f:\n",
    "#        writer = csv.DictWriter(f, fieldnames=headers)\n",
    "#        writer.writeheader()\n",
    "for genre in genre_set:\n",
    "    genre_data = genre_map[genre_map['Genre'] == genre]\n",
    "    i=0\n",
    "    df=pd.DataFrame(columns=headers)\n",
    "    for index, row in genre_data.iterrows():\n",
    "        if (i > 3000):\n",
    "            break\n",
    "        i = i+1\n",
    "        ## Retrieve track metadata from dataset\n",
    "        trackId = row['TrackId']\n",
    "        filename = os.path.join(get_track_path(trackId, dataset_path), trackId + \".h5\")\n",
    "        track = Track(trackId, filename)\n",
    "        track.setGenre(genre)\n",
    "        track.extractFeatures()\n",
    "\n",
    "        data = np.concatenate([[track.trackId], [track.tempo], track.segments_timbre, track.segments_pitches, track.segments_loudness_max, [track.beats_average_period], [track.genre]])\n",
    "        df.loc[0] = data\n",
    "        df['trackId']\n",
    "    df.to_csv(genre + '.csv', index=None, header=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn3-r31iPg3P"
   },
   "outputs": [],
   "source": [
    "# TODO: Do the extraction and show ouput data\n",
    "# TODO (Minor??): Save extracted data to a .csv file to remove necessity to run feature extraction code multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y8BVzNpAQdy0"
   },
   "source": [
    "## Training the Model\n",
    "\n",
    "Using the features extracted, a 3-layer Multilayer perceptron (MLP) is trained to determine a song's genre.\n",
    "\n",
    "![image.png](https://res.cloudinary.com/practicaldev/image/fetch/s--5hmoQpw5--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn-images-1.medium.com/max/720/1%2AvWRGnasRs2zo3GhTHlmIfg.jpeg)\n",
    "<center>A visualization of an MLP</center>\n",
    "\n",
    "A MLP is a class of feeedforward artificial neural network that utilizes backpropagation, a supervised learning technique used during training. Basically, the MLP will receive the features in the input layer and will return a set of probabilities for each genre in the output layer.\n",
    "\n",
    "To make the training more effective, we pre-process our data further.\n",
    "First we separate the features from the labels, then we standardized the values of the features to train our model faster. Standardization transforms the distribution of each feature to have a mean value of 0 and standard deviation of 1. Meanwhile, the output is converted into integers then transformed into a one-hot vector. One hot encoding is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction. We then split the inputs and the output labels into a training and test set.\n",
    "\n",
    "Afterwards, some hyperparameters are set which will be used by the model during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ukvvu6RCQsyt"
   },
   "outputs": [],
   "source": [
    "## Read extracted feature data and split into input and output.\n",
    "data = pd.read_csv('./test_data.csv')\n",
    "\n",
    "X = data.drop(['trackId', 'label'], axis=1)\n",
    "y = data['label']\n",
    "\n",
    "num_labels = len(np.unique(y))\n",
    "input_size = X.shape[1]\n",
    "\n",
    "# Standardize floats\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(X, dtype = float))\n",
    "\n",
    "# convert labels to one-hot vector\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 128\n",
    "hidden_units = 256\n",
    "dropout = 0.4\n",
    "epochs=100\n",
    "\n",
    "# Model is a 3-layer MLP with ReLU and dropout after each layer\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(hidden_units,input_dim=input_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Dense(hidden_units))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "\n",
    "# Output\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# Train the network\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "# validation\n",
    "loss, acc = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cGiZIezDRFUa"
   },
   "source": [
    "# Results\n",
    "\n",
    "We can measure how correct the model is by looking into the model loss and it's accuracy. Loss is a number indicating how bad the model's prediction is on a given sample. The loss should decrease as training continues. But too much training will overfit our model and increase the loss. Accuracy meanwhile determines how correct the predictions are. This is determined by using the model with a different set of inputs, the test data we separated earlier, and comparing the model's output with the actual answer. This should increase as training continues but again when the model is being trained for too long, the model will overfit and using the data from the test set will yield a lower accuracy.\n",
    "\n",
    "For comparison, we use Pandey's [1] MLP which yields an accuracy of about 65%.\n",
    "\n",
    "Just by changing the hyperparameters and adding some regularizers and other techniques to optimize the model, our model's accuracy increased to at maximum, **70.8%**.\n",
    "\n",
    "And after adding the **INSERT FEATURE HERE** and **INSERT OTHER FEATURE HERE**, we further increased the accuracy to **INSERT BETTER ACCURACY** here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))\n",
    "\n",
    "# Summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(loss)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "whTmx9N4RaFP"
   },
   "source": [
    "## Reference\n",
    "\n",
    "[1] Pandey, P. (2018, December 19). Music Genre Classification with Python. Retrieved from https://towardsdatascience.com/music-genre-classification-with-python-c714d032f0d8.\n",
    "\n",
    "[2] Thierry Bertin-Mahieux, Daniel P.W. Ellis, Brian Whitman, and Paul Lamere. The Million Song Dataset. In Proceedings of the 12th International Society for Music Information Retrieval Conference (ISMIR 2011), 2011.\n",
    "\n",
    "[3] Information and Software Engineering Group (IFS), Institute of Software Technology and Interactive Systems (ISIS),\n",
    "Vienna University of Technology. MSD Allmusic Genre Dataset (MAGD). Retrieved from http://www.ifs.tuwien.ac.at/mir/msd/download.html\n",
    "\n",
    "[4] Retrieved from https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-analysis/#timbre"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "EE286-FinalProject",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
